{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Identification\n",
    "\n",
    "안면 인식 관련하여 크게, Face Detection과 Face Identification으로 나뉜다. 둘은 비슷하지만 다르다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "현재 이 코드가 적힌 파일 위치에 facenet_pytorch이라는 폴더가 있고, 이를 모듈처럼 불러와 사용하는데,\n",
    "\n",
    "이것도 `__init__.py`라는 파일이 있어야 이렇게 모듈처럼 불러올 수 있고, 동일 폴더 내에 있어야 하는 등 여러 조건이 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 구글이 공개한 facenet이라는 AI 모델이 있는데, tensorflow로 작성된 것을 pytorch 형태로 공개하고 있다.\n",
    "# https://github.com/timesler/facenet-pytorch\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1, fixed_image_standardization, training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리가 봤었던 MNIST의 경우, 데이터가 이미지인데 excel에 숫자로 적혀 있어서 pandas로 불러와서 이를 torch로 바꿔주었으나,\n",
    "\n",
    "`featuresTrain = torch.from_numpy(features_train)`\n",
    "\n",
    "`targetsTrain = torch.from_numpy(target_train).type(torch.LongTensor)`\n",
    "\n",
    "`train = torch.utils.data.TensorDataset(featuresTrain,targetsTrain)`\n",
    "\n",
    "여기서는 이미지 파일이기 때문에 torchvision.datasets이라는 내장된 모듈을 사용해 간편하게 불러온다.\n",
    "\n",
    "그리고 한번 이미지를 align 해야 하는 과정이 필요하다.\n",
    "\n",
    "`dataset = datasets.ImageFolder(data_dir, transform=transforms.Resize((512, 512)))`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define run parameters\n",
    "\n",
    "The dataset should follow the VGGFace2/ImageNet-style directory layout. Modify `data_dir` to the location of the dataset on wish to finetune on.\n",
    "\n",
    "보통 input data 위치 및 하이퍼파라미터를 설정하는 것인데, 하이퍼 파라미터란 조정하는 수치값을 의미한다.\n",
    "\n",
    "epoch의 경우 같은 데이터로 학습을 몇 번 돌릴 것인지를 의미한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = './data/train'\n",
    "\n",
    "batch_size = 8\n",
    "epochs = 16\n",
    "workers = 0 if os.name == 'nt' else 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine if an nvidia GPU is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('Running on device: {}'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define MTCNN module\n",
    "\n",
    "See `help(MTCNN)` for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mtcnn = MTCNN(\n",
    "    image_size=160, margin=0, min_face_size=20,\n",
    "    thresholds=[0.6, 0.7, 0.7], factor=0.709,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = InceptionResnetV1(pretrained='vggface2', classify=True).eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(x):\n",
    "    return x[0]\n",
    "\n",
    "dataset = datasets.ImageFolder(data_dir)\n",
    "dataset.idx_to_class = {i:c for c, i in dataset.class_to_idx.items()}\n",
    "loader = DataLoader(dataset, collate_fn=collate_fn, num_workers=workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face detected with probability: 0.998145\n",
      "Face detected with probability: 0.999908\n",
      "Face detected with probability: 0.999996\n",
      "Face detected with probability: 0.998552\n",
      "Face detected with probability: 0.993009\n",
      "Face detected with probability: 0.999828\n",
      "Face detected with probability: 0.999999\n",
      "Face detected with probability: 0.999686\n",
      "Face detected with probability: 0.999639\n",
      "Face detected with probability: 0.999997\n",
      "Face detected with probability: 0.999999\n",
      "Face detected with probability: 0.999991\n",
      "Face detected with probability: 0.999993\n",
      "Face detected with probability: 0.999198\n",
      "Face detected with probability: 0.999426\n",
      "Face detected with probability: 0.999996\n",
      "Face detected with probability: 0.999999\n",
      "Face detected with probability: 0.999957\n",
      "Face detected with probability: 0.999995\n",
      "Face detected with probability: 0.999917\n",
      "Face detected with probability: 0.999325\n",
      "Face detected with probability: 0.999985\n",
      "Face detected with probability: 0.998141\n",
      "Face detected with probability: 0.999952\n",
      "Face detected with probability: 0.999968\n",
      "Face detected with probability: 0.999132\n",
      "Face detected with probability: 0.999968\n",
      "Face detected with probability: 0.999975\n",
      "Face detected with probability: 0.999495\n",
      "Face detected with probability: 0.999447\n",
      "Face detected with probability: 0.999995\n",
      "Face detected with probability: 0.999757\n",
      "Face detected with probability: 0.999955\n",
      "Face detected with probability: 0.997439\n",
      "Face detected with probability: 0.999678\n",
      "Face detected with probability: 0.999981\n",
      "Face detected with probability: 0.999668\n",
      "Face detected with probability: 0.999556\n",
      "Face detected with probability: 0.999735\n",
      "Face detected with probability: 0.999736\n",
      "Face detected with probability: 0.999994\n",
      "Face detected with probability: 0.993962\n",
      "Face detected with probability: 0.999187\n",
      "Face detected with probability: 0.999135\n",
      "Face detected with probability: 0.999309\n",
      "Face detected with probability: 0.999932\n",
      "Face detected with probability: 0.999169\n",
      "Face detected with probability: 0.999975\n",
      "Face detected with probability: 0.999306\n",
      "Face detected with probability: 0.999112\n"
     ]
    }
   ],
   "source": [
    "aligned = []\n",
    "names = []\n",
    "for x, y in loader:\n",
    "    x_aligned, prob = mtcnn(x, return_prob=True)\n",
    "    if x_aligned is not None:\n",
    "        print('Face detected with probability: {:8f}'.format(prob))\n",
    "        aligned.append(x_aligned)\n",
    "        names.append(dataset.idx_to_class[y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned = torch.stack(aligned).to(device)\n",
    "embeddings = resnet(aligned).detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 8631])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   IU          IU          IU          IU          IU  \\\n",
      "IU           0.000000  107.882195  116.826225  109.790085  127.843582   \n",
      "IU         107.882195    0.000000  101.853210   84.961960  129.613327   \n",
      "IU         116.826225  101.853210    0.000000  100.785233  114.849182   \n",
      "IU         109.790085   84.961960  100.785233    0.000000  126.902893   \n",
      "IU         127.843582  129.613327  114.849182  126.902893    0.000000   \n",
      "chanyoung  273.037567  240.848907  248.341812  265.641998  263.893494   \n",
      "chanyoung  256.509705  234.328918  237.744766  254.580994  247.749664   \n",
      "chanyoung  245.370026  225.247025  234.826843  236.462616  224.891830   \n",
      "chanyoung  257.587891  230.464661  245.854233  244.322739  230.348587   \n",
      "chanyoung  240.291946  236.347443  252.300751  236.352371  233.436066   \n",
      "eunwoo     251.081299  253.120438  258.984436  262.336182  252.492950   \n",
      "eunwoo     242.172272  241.057724  255.562332  245.530899  242.004196   \n",
      "eunwoo     215.473160  221.107590  230.559464  232.845078  236.518021   \n",
      "eunwoo     241.519272  247.565369  252.642258  255.342636  253.101791   \n",
      "eunwoo     262.139465  246.684006  261.565979  259.631561  268.698914   \n",
      "gaeri      216.522079  201.812958  218.867416  201.789413  205.535233   \n",
      "gaeri      232.405090  201.076309  210.618790  202.167114  232.234772   \n",
      "gaeri      230.065720  207.942703  217.281372  213.128510  230.408417   \n",
      "gaeri      262.911224  247.491943  259.290436  248.604385  270.497375   \n",
      "gaeri      227.656494  210.527802  216.539398  210.060944  206.406357   \n",
      "hayoung    211.862228  208.958618  172.305359  220.267334  185.322891   \n",
      "hayoung    208.860275  201.273026  164.356186  209.146545  171.213684   \n",
      "hayoung    192.407074  173.719849  166.552948  175.504074  161.179443   \n",
      "hayoung    214.638702  197.385849  191.943710  207.929153  197.521057   \n",
      "hayoung    219.035141  189.643768  189.994217  206.223358  208.523636   \n",
      "jaewon     242.596237  203.216370  201.141357  215.319397  233.015305   \n",
      "jaewon     233.294373  198.593124  202.491547  203.912476  223.702057   \n",
      "jaewon     231.848984  189.646469  198.246368  197.309708  212.234634   \n",
      "jaewon     237.839661  200.945068  205.260437  211.291306  225.441162   \n",
      "jaewon     248.541428  225.460846  213.063919  220.826736  241.491394   \n",
      "jonggook   247.188812  229.031586  247.521515  236.467300  232.050735   \n",
      "jonggook   261.124695  241.898254  257.888733  250.373413  252.249054   \n",
      "jonggook   260.409851  238.018005  249.409515  236.585281  233.776886   \n",
      "jonggook   250.567108  233.338120  249.988953  232.431625  250.186310   \n",
      "jonggook   243.796783  222.206207  237.738190  237.996414  236.697342   \n",
      "min        240.631042  209.302292  220.795288  230.464966  217.317841   \n",
      "min        250.267776  230.469650  241.357620  250.424591  228.564026   \n",
      "min        239.200958  219.342392  228.766235  231.398849  218.597733   \n",
      "min        259.191620  229.814865  253.207901  244.308197  242.235413   \n",
      "min        237.819946  226.517410  228.543335  227.718506  214.809021   \n",
      "soohyang   168.035858  154.605118  166.112183  157.460556  190.348053   \n",
      "soohyang   198.519211  196.747025  179.048706  178.870468  195.186813   \n",
      "soohyang   186.757233  173.818665  175.285645  163.402420  192.446457   \n",
      "soohyang   169.959061  179.072739  168.980743  165.067795  184.244019   \n",
      "soohyang   178.611847  161.218338  163.613724  157.300003  190.198196   \n",
      "younha     155.581177  148.166870  139.312668  135.858749  139.607513   \n",
      "younha     161.866516  162.119415  152.134323  162.839493  121.496529   \n",
      "younha     189.165512  176.346893  181.302399  175.659378  165.428314   \n",
      "younha     203.613937  206.722946  182.089783  202.928696  165.966492   \n",
      "younha     191.801544  187.935745  172.396393  165.230484  157.805161   \n",
      "\n",
      "            chanyoung   chanyoung   chanyoung   chanyoung   chanyoung  ...  \\\n",
      "IU         273.037567  256.509705  245.370026  257.587891  240.291946  ...   \n",
      "IU         240.848907  234.328918  225.247025  230.464661  236.347443  ...   \n",
      "IU         248.341812  237.744766  234.826843  245.854233  252.300751  ...   \n",
      "IU         265.641998  254.580994  236.462616  244.322739  236.352371  ...   \n",
      "IU         263.893494  247.749664  224.891830  230.348587  233.436066  ...   \n",
      "chanyoung    0.000000   95.304520  148.124039  149.029938  191.936584  ...   \n",
      "chanyoung   95.304520    0.000000  136.992508  158.711807  181.592194  ...   \n",
      "chanyoung  148.124039  136.992508    0.000000  106.128098  163.627136  ...   \n",
      "chanyoung  149.029938  158.711807  106.128098    0.000000  158.106262  ...   \n",
      "chanyoung  191.936584  181.592194  163.627136  158.106262    0.000000  ...   \n",
      "eunwoo     188.325974  194.909164  225.919662  225.457779  172.295822  ...   \n",
      "eunwoo     213.720398  200.544632  231.100693  217.725891  153.146912  ...   \n",
      "eunwoo     205.705933  201.216660  238.974258  247.497116  179.378616  ...   \n",
      "eunwoo     218.440994  232.225769  261.627380  250.944214  193.603531  ...   \n",
      "eunwoo     219.470917  223.684769  257.919067  238.048813  190.263855  ...   \n",
      "gaeri      196.505920  176.574173  156.212219  193.528595  194.673050  ...   \n",
      "gaeri      225.163834  218.032486  214.709839  231.853119  238.675339  ...   \n",
      "gaeri      211.444336  196.292923  179.144135  212.650223  232.417358  ...   \n",
      "gaeri      247.615219  233.599487  214.984482  244.626831  255.528046  ...   \n",
      "gaeri      210.263992  182.207474  171.973633  200.005203  210.895905  ...   \n",
      "hayoung    226.438889  229.826187  253.920013  251.412231  260.252197  ...   \n",
      "hayoung    223.985428  228.317627  240.912994  229.486450  250.480301  ...   \n",
      "hayoung    253.434845  252.290070  233.629639  230.900681  232.346466  ...   \n",
      "hayoung    199.119904  211.398605  211.189285  199.170670  224.559540  ...   \n",
      "hayoung    179.526031  196.458282  224.649857  204.787537  228.563171  ...   \n",
      "jaewon     224.891296  218.833389  261.817963  256.841461  269.891174  ...   \n",
      "jaewon     234.379471  222.054871  253.971497  251.174683  255.712357  ...   \n",
      "jaewon     212.243668  204.173920  237.692719  229.418625  240.615707  ...   \n",
      "jaewon     189.401382  200.512344  218.527496  211.855759  241.380402  ...   \n",
      "jaewon     267.762573  244.887817  282.793518  295.074554  290.514343  ...   \n",
      "jonggook   226.557602  191.572220  192.530655  207.444550  183.550247  ...   \n",
      "jonggook   235.027969  212.083740  186.006516  212.188385  193.493454  ...   \n",
      "jonggook   206.654861  170.636246  159.494522  174.465149  168.888809  ...   \n",
      "jonggook   240.645447  204.817505  209.473831  222.508896  203.365585  ...   \n",
      "jonggook   214.272491  182.582611  196.147949  226.361771  197.466400  ...   \n",
      "min        212.322525  179.048447  184.235092  203.334595  226.271881  ...   \n",
      "min        220.494415  200.347015  200.202866  219.013199  238.911316  ...   \n",
      "min        234.484848  200.185150  185.371826  210.896698  221.929733  ...   \n",
      "min        216.936569  199.392090  182.732285  192.363724  224.567352  ...   \n",
      "min        263.061981  235.970444  222.078583  232.336365  230.035690  ...   \n",
      "soohyang   262.798340  242.171097  233.429764  238.711395  246.789276  ...   \n",
      "soohyang   302.889130  291.512604  255.314651  259.505829  266.847717  ...   \n",
      "soohyang   265.249908  258.174683  233.086945  215.700027  224.971191  ...   \n",
      "soohyang   292.100616  284.902222  257.781952  257.593903  258.519806  ...   \n",
      "soohyang   277.019440  262.196411  234.164001  223.946121  238.707336  ...   \n",
      "younha     273.294617  268.393890  250.240463  252.226944  256.922363  ...   \n",
      "younha     268.512207  247.933731  228.786880  241.996094  248.908188  ...   \n",
      "younha     241.071075  232.247055  216.484467  223.411606  229.978912  ...   \n",
      "younha     259.148254  238.183075  247.942566  266.358765  264.711212  ...   \n",
      "younha     265.247070  251.811401  231.448105  237.754623  237.713287  ...   \n",
      "\n",
      "             soohyang    soohyang    soohyang    soohyang    soohyang  \\\n",
      "IU         168.035858  198.519211  186.757233  169.959061  178.611847   \n",
      "IU         154.605118  196.747025  173.818665  179.072739  161.218338   \n",
      "IU         166.112183  179.048706  175.285645  168.980743  163.613724   \n",
      "IU         157.460556  178.870468  163.402420  165.067795  157.300003   \n",
      "IU         190.348053  195.186813  192.446457  184.244019  190.198196   \n",
      "chanyoung  262.798340  302.889130  265.249908  292.100616  277.019440   \n",
      "chanyoung  242.171097  291.512604  258.174683  284.902222  262.196411   \n",
      "chanyoung  233.429764  255.314651  233.086945  257.781952  234.164001   \n",
      "chanyoung  238.711395  259.505829  215.700027  257.593903  223.946121   \n",
      "chanyoung  246.789276  266.847717  224.971191  258.519806  238.707336   \n",
      "eunwoo     271.122864  301.428619  263.815704  293.062408  291.831360   \n",
      "eunwoo     272.155426  301.732483  255.736710  292.911346  276.897827   \n",
      "eunwoo     241.147141  286.751251  250.905792  255.741043  267.458862   \n",
      "eunwoo     272.195038  290.776764  264.277924  268.252075  288.212036   \n",
      "eunwoo     256.186920  289.084717  257.203186  270.903015  278.187469   \n",
      "gaeri      208.730362  253.919327  248.068924  224.883575  242.039703   \n",
      "gaeri      219.296082  254.005646  250.173599  218.352219  231.583817   \n",
      "gaeri      227.141891  255.789017  257.039429  225.550903  241.061417   \n",
      "gaeri      242.517395  273.840790  272.875458  231.931549  266.560150   \n",
      "gaeri      231.736740  243.827896  243.686569  227.056305  236.403534   \n",
      "hayoung    244.105209  268.801483  244.724380  246.528931  267.438171   \n",
      "hayoung    235.166641  263.987671  234.119797  240.995483  251.345078   \n",
      "hayoung    208.944763  234.810959  214.340561  200.304764  215.527863   \n",
      "hayoung    209.610641  255.491516  216.118134  207.606903  235.703491   \n",
      "hayoung    197.280045  260.621979  213.733444  229.839996  240.946518   \n",
      "jaewon     236.714355  284.858826  253.332809  273.116669  257.245422   \n",
      "jaewon     225.773285  286.710693  246.105087  260.609985  251.609604   \n",
      "jaewon     225.876221  272.751465  236.985657  255.508728  239.411392   \n",
      "jaewon     233.856430  285.273163  244.826492  256.054382  251.786301   \n",
      "jaewon     247.633286  300.530609  273.579834  286.938690  279.304352   \n",
      "jonggook   249.307129  255.148819  239.861847  262.671539  243.130539   \n",
      "jonggook   272.603577  258.485535  256.785950  264.466248  249.100800   \n",
      "jonggook   255.100403  251.946762  243.696594  270.258331  247.015701   \n",
      "jonggook   238.464249  248.430038  240.544113  255.176971  238.766144   \n",
      "jonggook   247.735077  254.183487  254.721176  260.589172  243.058319   \n",
      "min        241.125290  259.620453  246.239578  270.965576  239.051590   \n",
      "min        246.417236  263.803711  258.689697  269.323242  266.372253   \n",
      "min        237.956711  246.485703  238.272537  269.185272  240.461121   \n",
      "min        228.841370  246.865692  229.132965  254.379730  242.718887   \n",
      "min        244.363373  246.884216  230.521820  264.959534  233.567139   \n",
      "soohyang     0.000000  177.110016  143.648132  140.272690  146.555878   \n",
      "soohyang   177.110016    0.000000  130.154099  138.480576  130.481583   \n",
      "soohyang   143.648132  130.154099    0.000000  148.285355   96.970299   \n",
      "soohyang   140.272690  138.480576  148.285355    0.000000  141.899277   \n",
      "soohyang   146.555878  130.481583   96.970299  141.899277    0.000000   \n",
      "younha     192.279648  216.686279  196.907288  196.952530  193.769165   \n",
      "younha     213.187973  222.943726  225.743271  212.198135  213.983505   \n",
      "younha     212.851822  253.035645  223.046722  232.135040  222.952316   \n",
      "younha     235.207657  246.073883  248.371918  237.161163  249.636322   \n",
      "younha     214.560547  233.937424  204.852570  229.808136  212.994614   \n",
      "\n",
      "               younha      younha      younha      younha      younha  \n",
      "IU         155.581177  161.866516  189.165512  203.613937  191.801544  \n",
      "IU         148.166870  162.119415  176.346893  206.722946  187.935745  \n",
      "IU         139.312668  152.134323  181.302399  182.089783  172.396393  \n",
      "IU         135.858749  162.839493  175.659378  202.928696  165.230484  \n",
      "IU         139.607513  121.496529  165.428314  165.966492  157.805161  \n",
      "chanyoung  273.294617  268.512207  241.071075  259.148254  265.247070  \n",
      "chanyoung  268.393890  247.933731  232.247055  238.183075  251.811401  \n",
      "chanyoung  250.240463  228.786880  216.484467  247.942566  231.448105  \n",
      "chanyoung  252.226944  241.996094  223.411606  266.358765  237.754623  \n",
      "chanyoung  256.922363  248.908188  229.978912  264.711212  237.713287  \n",
      "eunwoo     257.292999  266.388275  240.120499  252.780334  241.782211  \n",
      "eunwoo     251.556656  253.602066  230.186981  248.305862  238.159943  \n",
      "eunwoo     252.734940  260.972565  241.879852  248.772095  249.112366  \n",
      "eunwoo     264.128876  271.267029  251.762512  276.404694  263.226562  \n",
      "eunwoo     268.854431  275.179657  257.336578  276.451019  268.845520  \n",
      "gaeri      217.258896  208.010117  197.161835  217.590469  216.211975  \n",
      "gaeri      230.997375  230.447540  246.099564  248.744064  250.635513  \n",
      "gaeri      237.473450  232.781036  232.484283  239.333435  249.324097  \n",
      "gaeri      278.618439  266.145782  277.292419  281.301300  285.936707  \n",
      "gaeri      216.901596  195.840469  205.444519  201.312012  212.745499  \n",
      "hayoung    207.598465  201.973480  207.323654  213.349106  210.466064  \n",
      "hayoung    193.491486  190.981445  191.109467  206.432159  197.073578  \n",
      "hayoung    167.283234  167.987976  153.822113  208.232605  173.111771  \n",
      "hayoung    221.833420  216.847626  221.787460  246.189545  229.833649  \n",
      "hayoung    208.933533  230.281708  219.600967  239.241455  221.595261  \n",
      "jaewon     211.845535  247.502151  227.261993  235.639130  227.964432  \n",
      "jaewon     203.145691  236.553650  208.030502  216.405441  206.263657  \n",
      "jaewon     203.139633  230.519806  208.261917  219.170746  211.487000  \n",
      "jaewon     220.547867  249.601715  218.171204  245.996338  233.562256  \n",
      "jaewon     232.808823  261.101929  251.032974  231.475433  237.456833  \n",
      "jonggook   246.841537  211.293732  220.478180  231.945465  229.126007  \n",
      "jonggook   267.456238  237.879044  256.764679  263.666901  258.808533  \n",
      "jonggook   254.208206  223.645096  224.072433  242.473129  230.686554  \n",
      "jonggook   247.085159  231.818909  235.013596  240.876984  237.701828  \n",
      "jonggook   264.046448  225.520950  239.562576  238.077286  256.243866  \n",
      "min        236.272720  203.769043  211.802490  226.243286  215.023346  \n",
      "min        241.974380  202.949234  211.654099  207.603958  217.350418  \n",
      "min        244.722412  209.727051  226.287323  227.679123  221.030548  \n",
      "min        257.395203  236.524078  228.503708  248.913910  238.061142  \n",
      "min        210.155090  186.156509  212.361221  198.210495  171.984879  \n",
      "soohyang   192.279648  213.187973  212.851822  235.207657  214.560547  \n",
      "soohyang   216.686279  222.943726  253.035645  246.073883  233.937424  \n",
      "soohyang   196.907288  225.743271  223.046722  248.371918  204.852570  \n",
      "soohyang   196.952530  212.198135  232.135040  237.161163  229.808136  \n",
      "soohyang   193.769165  213.983505  222.952316  249.636322  212.994614  \n",
      "younha       0.000000  129.095001  126.846863  169.146011   98.796890  \n",
      "younha     129.095001    0.000000  144.415024  148.425735  142.134613  \n",
      "younha     126.846863  144.415024    0.000000  181.711700  104.799194  \n",
      "younha     169.146011  148.425735  181.711700    0.000000  160.909439  \n",
      "younha      98.796890  142.134613  104.799194  160.909439    0.000000  \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50 rows x 50 columns]\n"
     ]
    }
   ],
   "source": [
    "dists = [[(e1 - e2).norm().item() for e2 in embeddings] for e1 in embeddings]\n",
    "print(pd.DataFrame(dists, columns=names, index=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IU',\n",
       " 'IU',\n",
       " 'IU',\n",
       " 'IU',\n",
       " 'IU',\n",
       " 'chanyoung',\n",
       " 'chanyoung',\n",
       " 'chanyoung',\n",
       " 'chanyoung',\n",
       " 'chanyoung',\n",
       " 'eunwoo',\n",
       " 'eunwoo',\n",
       " 'eunwoo',\n",
       " 'eunwoo',\n",
       " 'eunwoo',\n",
       " 'gaeri',\n",
       " 'gaeri',\n",
       " 'gaeri',\n",
       " 'gaeri',\n",
       " 'gaeri',\n",
       " 'hayoung',\n",
       " 'hayoung',\n",
       " 'hayoung',\n",
       " 'hayoung',\n",
       " 'hayoung',\n",
       " 'jaewon',\n",
       " 'jaewon',\n",
       " 'jaewon',\n",
       " 'jaewon',\n",
       " 'jaewon',\n",
       " 'jonggook',\n",
       " 'jonggook',\n",
       " 'jonggook',\n",
       " 'jonggook',\n",
       " 'jonggook',\n",
       " 'min',\n",
       " 'min',\n",
       " 'min',\n",
       " 'min',\n",
       " 'min',\n",
       " 'soohyang',\n",
       " 'soohyang',\n",
       " 'soohyang',\n",
       " 'soohyang',\n",
       " 'soohyang',\n",
       " 'younha',\n",
       " 'younha',\n",
       " 'younha',\n",
       " 'younha',\n",
       " 'younha']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings.tolist())\n",
    "names\n",
    "# dataset.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = []\n",
    "for n in names:\n",
    "    idxs.append(dataset.class_to_idx[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=True, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='linear', probability=True)\n",
    "clf.fit(embeddings.tolist(), idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = './data/test'\n",
    "\n",
    "batch_size = 8\n",
    "epochs = 16\n",
    "workers = 0 if os.name == 'nt' else 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mtcnn = MTCNN(\n",
    "    image_size=160, margin=0, min_face_size=20,\n",
    "    thresholds=[0.6, 0.7, 0.7], factor=0.709,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = InceptionResnetV1(pretrained='vggface2', classify=True).eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(x):\n",
    "    return x[0]\n",
    "\n",
    "dataset = datasets.ImageFolder(data_dir)\n",
    "dataset.idx_to_class = {i:c for c, i in dataset.class_to_idx.items()}\n",
    "loader = DataLoader(dataset, collate_fn=collate_fn, num_workers=workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned = []\n",
    "names = []\n",
    "for x, y in loader:\n",
    "    x_aligned, prob = mtcnn(x, return_prob=True)\n",
    "    if x_aligned is not None:\n",
    "        aligned.append(x_aligned)\n",
    "        names.append(dataset.idx_to_class[y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned = torch.stack(aligned).to(device)\n",
    "embeddings = resnet(aligned).detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3700292943130865\n",
      "0\n",
      "0.25953407422929314\n",
      "0\n",
      "0.4593012523801784\n",
      "1\n",
      "0.4175110310458948\n",
      "1\n",
      "0.3905814114825507\n",
      "2\n",
      "0.40632669030914936\n",
      "2\n",
      "0.492342347191165\n",
      "3\n",
      "0.48437317038974836\n",
      "3\n",
      "0.4963243501112441\n",
      "4\n",
      "0.4949887051732227\n",
      "4\n",
      "0.4251502244137099\n",
      "5\n",
      "0.33385957680198386\n",
      "5\n",
      "0.4594991284899076\n",
      "6\n",
      "0.5031112486817445\n",
      "6\n",
      "0.36392488109676113\n",
      "7\n",
      "0.45448238090462456\n",
      "7\n",
      "0.31081664712768126\n",
      "8\n",
      "0.40856844596082215\n",
      "8\n",
      "0.18158578095254413\n",
      "0\n",
      "0.21434905549000105\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in clf.predict_proba(embeddings.tolist()):\n",
    "    print(max(i))\n",
    "    print(np.argmax(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perfom MTCNN facial detection\n",
    "\n",
    "Iterate through the DataLoader object and obtained cropped faces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset = datasets.ImageFolder(data_dir, transform=transforms.Resize((512, 512)))\n",
    "dataset.samples = [\n",
    "    (p, p.replace(data_dir, data_dir + '_aligned')) for p, _ in dataset.samples\n",
    "]\n",
    "        \n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    num_workers=workers,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=training.collate_pil\n",
    ")\n",
    "\n",
    "for i, (x, y) in enumerate(loader):\n",
    "    mtcnn(x, save_path=y)\n",
    "    print('\\rBatch {} of {}'.format(i + 1, len(loader)), end='')\n",
    "    \n",
    "# Remove mtcnn to reduce GPU memory usage\n",
    "del mtcnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Inception Resnet V1 module\n",
    "\n",
    "See `help(InceptionResnetV1)` for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "resnet = InceptionResnetV1(\n",
    "    classify=False,\n",
    "    pretrained='vggface2'\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(dataset.class_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define optimizer, scheduler, dataset, and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(resnet.parameters(), lr=0.001)\n",
    "scheduler = MultiStepLR(optimizer, [5, 10])\n",
    "\n",
    "# trans = transforms.Compose([\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "#     transforms.RandomErasing(),\n",
    "# ])\n",
    "\n",
    "trans = transforms.Compose([\n",
    "    np.float32,\n",
    "    transforms.ToTensor(),\n",
    "    fixed_image_standardization\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(data_dir + '_aligned', transform=trans)\n",
    "img_inds = np.arange(len(dataset))\n",
    "np.random.shuffle(img_inds)\n",
    "train_inds = img_inds[:int(0.8 * len(img_inds))]\n",
    "val_inds = img_inds[int(0.8 * len(img_inds)):]\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset,\n",
    "    num_workers=workers,\n",
    "    batch_size=batch_size,\n",
    "    sampler=SubsetRandomSampler(train_inds)\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    dataset,\n",
    "    num_workers=workers,\n",
    "    batch_size=batch_size,\n",
    "    sampler=SubsetRandomSampler(val_inds)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define loss and evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "metrics = {\n",
    "    'fps': training.BatchTimer(),\n",
    "    'acc': training.accuracy\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "writer = SummaryWriter()\n",
    "writer.iteration, writer.interval = 0, 10\n",
    "\n",
    "print('\\n\\nInitial')\n",
    "print('-' * 10)\n",
    "resnet.eval()\n",
    "training.pass_epoch(\n",
    "    resnet, loss_fn, val_loader,\n",
    "    batch_metrics=metrics, show_running=True, device=device,\n",
    "    writer=writer\n",
    ")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print('\\nEpoch {}/{}'.format(epoch + 1, epochs))\n",
    "    print('-' * 10)\n",
    "\n",
    "    resnet.train()\n",
    "    training.pass_epoch(\n",
    "        resnet, loss_fn, train_loader, optimizer, scheduler,\n",
    "        batch_metrics=metrics, show_running=True, device=device,\n",
    "        writer=writer\n",
    "    )\n",
    "\n",
    "    resnet.eval()\n",
    "    training.pass_epoch(\n",
    "        resnet, loss_fn, val_loader,\n",
    "        batch_metrics=metrics, show_running=True, device=device,\n",
    "        writer=writer\n",
    "    )\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset)\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "for x, idx in loader:\n",
    "    X += resnet(x.cuda()).tolist()\n",
    "    y += idx.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='linear', probability=True)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mtcnn = MTCNN(\n",
    "    image_size=160, margin=0, min_face_size=20,\n",
    "    thresholds=[0.6, 0.7, 0.7], factor=0.709,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = './data/test'\n",
    "\n",
    "dataset = datasets.ImageFolder(data_dir, transform=transforms.Resize((512, 512)))\n",
    "dataset.samples = [\n",
    "    (p, p.replace(data_dir, data_dir + '_aligned')) for p, _ in dataset.samples\n",
    "]\n",
    "\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    num_workers=workers,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=training.collate_pil\n",
    ")\n",
    "\n",
    "for i, (x, y) in enumerate(loader):\n",
    "    mtcnn(x, save_path=y)\n",
    "    print('\\rBatch {} of {}'.format(i + 1, len(loader)), end='')\n",
    "    \n",
    "# Remove mtcnn to reduce GPU memory usage\n",
    "del mtcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# trans = transforms.Compose([\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "#     transforms.RandomErasing(),\n",
    "# ])\n",
    "\n",
    "trans = transforms.Compose([\n",
    "    np.float32,\n",
    "    transforms.ToTensor(),\n",
    "    fixed_image_standardization\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(data_dir + '_aligned', transform=trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset)\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "for x, idx in loader:\n",
    "    X += resnet(x.cuda()).tolist()\n",
    "    y += idx.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in clf.predict_proba(X):\n",
    "    print(np.argmax(i), i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make Classification Model with SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_loader = DataLoader(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "for i in data_loader:\n",
    "    X += resnet(i[0].cuda()).tolist()\n",
    "    y.append(i[1].cuda().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='linear', probability=True)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mtcnn = MTCNN(\n",
    "    image_size=160, margin=0, min_face_size=20,\n",
    "    thresholds=[0.6, 0.7, 0.7], factor=0.709,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def collate_fn(x):\n",
    "    return x[0]\n",
    "\n",
    "dataset = datasets.ImageFolder('./data/test')\n",
    "dataset.idx_to_class = {i:c for c, i in dataset.class_to_idx.items()}\n",
    "loader = DataLoader(dataset, collate_fn=collate_fn, num_workers=workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "aligned = []\n",
    "names = []\n",
    "for x, y in loader:\n",
    "    x_aligned, prob = mtcnn(x, return_prob=True)\n",
    "    if x_aligned is not None:\n",
    "        print('Face detected with probability: {:8f}'.format(prob))\n",
    "        aligned.append(x_aligned)\n",
    "        names.append(dataset.idx_to_class[y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "type(aligned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "aligned = torch.stack(aligned).to(device)\n",
    "embeddings = resnet(aligned.cuda()).detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(embeddings.tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(clf.predict_proba(embeddings.tolist()))\n",
    "print(names)\n",
    "print(dataset.idx_to_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
